---
title: "Summary"
author: "Number Guessing Team"
date: "17/12/2020"
output:
  html_document:
    highlight: kate
    theme: flatly
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# --- Setup --- #

# Load libraries
suppressMessages(library(tidyverse))
library(tidyverse)
library(RColorBrewer)
library(knitr)
library(lme4)

# Load data from data processing 
guesses <- read.csv('../data/guesses_processed.csv')
games <- read.csv('../data/games_processed.csv')
users <- read.csv('../data/users_processed.csv')

# Load simulation data
guesses.binary = read.csv('../data/guesses_binary_search.csv')
guesses.random = read.csv('../data/guesses_random_search.csv')

# Create color palette
col.pal <- brewer.pal(6, "Set1")

color.human = col.pal[2]
color.binary = col.pal[3]
color.random = col.pal[1]
```

# 1. How optimal are player strategies?

In order to measure player performance, we calculate the **Expected Information Gain (EIG)** of each guess. This is a measure of how many candidates you would expect the player to eliminate with this guess. The higher the better.

The plot below shows **Expected Information Gain** for the participants' data compared to two different strategies: **Random Guessing** (red) and **Binary Search** (green). 

```{r}

guesses %>%
  ggplot(aes(x = EIG)) + 
  geom_density(data = guesses.binary,
    color=color.binary, size=1) +
  geom_density(data = guesses.random,
    color=color.random, size=1) +
  geom_density(color=color.human, size=1) +
  theme_minimal() +
  labs(
    title="Distribution of Expected Information Gain",
    x = "Expected Information Gain",
    y = "Density"
  )


```

```{r}

## Another draft of the same chart
guesses %>%
  ggplot(aes(x = EIG)) +
  geom_density(size=0.5, data = guesses,
               fill=color.human, color=color.human, alpha=0.8) +
  geom_density(size=0.5, data = guesses.binary,
               fill=color.binary, color=color.binary, alpha=0.05) +
  geom_density(size=0.5, data = guesses.random,
               fill=color.random, color=color.random, alpha=0.05) +

  theme_minimal() +
  labs(
    title="Mean EIG across different games",
    x = "EIG",
    y = "Density",
    color = "Strategy"
  )

```

Human guesses show high variance in EIG, but most guesses are slightly better than would be expected by chance, and not as good as would be expected by binary search.

We can compare how well participants are doing compared to binary search by dividing the EIG of each participant guess by the EIG that an optimal guess would have produced. Let's call this **Relative Expected Information Gain (REIG)** as it is EIG *relative to* the optimal EIG.

**Note: this is clearly an awful name and feel free to change it**

We can plot relative EIG for each strategy. REIG for Optimal strategy is always 1 by definition.

```{r}

guesses %>%
  ggplot(aes(x = EIG.relative)) +
  geom_vline(size = 1, xintercept=1, color = color.binary) +
  geom_density(data = guesses.random,
    color=color.random, size=0.5, fill = color.random, alpha=0.1) +
  geom_density(size=0.5, color=color.human, fill=color.human, alpha=0.1) +
  theme_minimal() +
  labs(
    title="Mean Relative EIG across different games",
    x = "Relative EIG",
    y = "Density"
  )

```

```{r}

guesses %>%
  mutate(eig.bin = cut_interval(EIG.relative, length=0.1,
                                labels = seq(0.1, 1, 0.1))
         ) %>%
  group_by(eig.bin) %>%
  summarise(prop=n()/ nrow(guesses)) %>%
  ggplot(aes(x = eig.bin, y = prop)) + 
  geom_bar(stat = "identity", fill=color.human) +
  theme_minimal() +
  labs(
    title="Relative EIG binned",
    x = "EIG relative to binary search",
    y = "Proportion of guesses"
  )

```

```{r}

random.summary <- guesses.random %>%
  filter(is.na(EIG.relative) == F) %>%
  mutate(eig.bin = as.factor(floor(EIG.relative * 10) / 10)
         ) %>%
  group_by(eig.bin) %>%
  summarise(prop=n()/ nrow(guesses.random))%>%
  mutate(dataset = "Random")


human.summary <- guesses %>%
  mutate(eig.bin = as.factor(floor(EIG.relative * 10) / 10)
         ) %>%
  group_by(eig.bin) %>%
  summarise(prop=n()/ nrow(guesses)) %>%
  mutate(dataset = "Participants")


binary.summary <- guesses.binary %>%
  filter(is.na(EIG.relative) == F) 

binary.summary <- binary.summary %>%
  mutate(eig.bin = as.factor(floor(EIG.relative * 10) / 10)
         ) %>%
  group_by(eig.bin) %>%
  summarise(prop=n()/ nrow(binary.summary))%>%
  mutate(dataset = "Binary Search")

guesses.summary = rbind(random.summary, binary.summary, human.summary)


guesses.summary %>%
  mutate(
    dataset = factor(dataset,
                     levels = c("Random", "Participants", "Binary Search"))
    ) %>%
  ggplot(aes(x = eig.bin, y = prop, fill = dataset)) + 
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  scale_fill_brewer(palette="Set1") +
  ylim(0,1) +
  labs(
    title="Relative EIG binned",
    x = "EIG relative to binary search",
    y = "Proportion of guesses"
  )


levels(guesses.summary$eig.bin)
```


# 2 Do users improve over time?

We can then look at whether users' REIG improves the more games they play.

```{r}

games %>%
  filter(no_user_games > 2) %>%
  ggplot(aes(game_index, EIG.relative)) +
  stat_summary_bin(fun.data="mean_cl_boot",
                   geom="pointrange",
                   binwidth = 5,
                   color=color.human) +
  geom_smooth(method = 'lm', formula = y~x, color=color.human) + 
  geom_hline(yintercept = guesses.random %>%
                          pull(EIG.relative) %>% mean(na.rm=T),
             color = color.random,
             size = 1,
             linetype = "dashed"
  )+
  geom_hline(yintercept = guesses.binary %>%
                          pull(EIG.relative) %>% mean(na.rm=T),
             color = color.binary,
             size = 1,
             linetype = "dashed"
  )+
  theme_minimal() + 
  labs(
    title = "User performance across games",
    x = "No. previous games played by user",
    y = "Relative Expected Information Gain"
  )

```

It looks at first as though performance improves a lot over time. However, this could also be due to the fact that players who play for longer happen to be good.

Let's look at the trajectory of players who play over 50 games.

```{r}
games %>%
  filter(no_user_games > 50) %>%
  ggplot(aes(game_index, EIG.relative)) +
  # geom_smooth(method = 'lm', formula = y~x) + 
  geom_smooth(method = 'lm', formula = y~x,
              mapping=aes(color=factor(user)),
              se=F) + 
  geom_hline(yintercept = guesses.random %>%
                          pull(EIG.relative) %>% mean(na.rm=T),
             color = color.random
  )+
  geom_hline(yintercept = guesses.binary %>%
                          pull(EIG.relative) %>% mean(na.rm=T),
             color = color.binary
  )+
  theme_minimal() + 
  labs(
    title="Mean REIG vs n-th game for longest playing users",
    x = "No. previous games played by user",
    y = "Mean EIG relative to binary search"
  ) + 
  theme(
    legend.position = "none"
  )
  
```

These lines of best fit show that these players are not improving at all.

Let's look at players relative mean EIG *relative* (again) to their own mean REIG across all games. Essentially let's ask, how did this users' performance compare to their mean performance across games.

```{r}

games <- merge(games, 
               users %>% select(user, EIG.relative) %>%
                 rename(EIG.relative.user = EIG.relative))

games %>%
  mutate(
    EIG.relative.self = EIG.relative / EIG.relative.user
  ) %>%
  filter(no_user_games > 2) %>%
  ggplot(aes(game_index, EIG.relative.self)) +
  stat_summary_bin(fun.data="mean_cl_boot",
                   geom="pointrange",
                   binwidth = 5,
                   color=color.human) +
  geom_smooth(method = 'lm', formula = y~x, color=color.human) + 
  theme_minimal() + 
  labs(
    title="REIG normalised to user mean for n-th game of user",
    x = "No. previous games played by user",
    y = "REIG vs career mean"
  )

```

Now we can see the effect is still positive, but a lot smaller than it originally appeared, and perhaps not bigger than the standard error (shaded).

## 2.2 Linear Models

Let's run some models and find out.

**Simple Model**

A simple model with no control for user shows a **very** convincing effect of game_index on relative EIG. F(1, 198485) = 606.2, p<0.001.

```{r}

m.EIG.gi <- lm(EIG.relative ~ game_index, data=guesses)
summary(m.EIG.gi)

```

**LMEM Random Intercepts**

A Linear Mixed Effect Model with random intercepts for participants shows an attenuated effect. A likelihood ratio test against a null model with the same random effect structure but no effect of game index showed an attenuated effect X^2(1) = 8.47, p = 0.004. You would expect a 1% improvement in REIG for every ~35 games played.

```{r}

guesses$user <- as.factor(guesses$user)

lmm.EIG.gi <- lmer(EIG.relative ~ game_index + (1 | user), data=guesses)

summary(lmm.EIG.gi)

# null model
lmm.EIG.gi.null <- lmer(EIG.relative ~ (1 | user), data=guesses)

anova(lmm.EIG.gi, lmm.EIG.gi.null)

0.01 / 2.833e-04

```

**LMEM Random Intercepts + slopes**

A model with random intercepts & slopes for for participants shows no effect of game_index on REIG. LRT with a null model showed that game index did not significantly predict model fit X^2(1) = 0.916, p = 0.338.

```{r}
lmm.EIG.gi.slopes <- lmer(EIG.relative ~ game_index + (game_index | user), data=guesses)

summary(lmm.EIG.gi.slopes)

# null model
lmm.EIG.gi.slopes.null <- lmer(EIG.relative ~ (game_index | user), data=guesses)

anova(lmm.EIG.gi.slopes, lmm.EIG.gi.slopes.null)
```

The full model with random slopes and intercepts is theoretically justified, as it is likely that different participants would not only start at a different level of ability at the game, but would also learn at different rates. Therefore, we conclude that there is not enough evidence to reject the null hypothesis that participants do not improve at TNGG over games played.

## 2.3. Discussion

Why not?

- Different users on the same device
- Took too long between turns
- Maybe the strategy is hard to learn from experience? 
- It's not fun to play a game whose analytic solution you understand

