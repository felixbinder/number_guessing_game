---
title: "Analysis"
author: "Number Guessing Team"
date: "017/12/2020"
output:
  html_document:
    highlight: kate
    theme: flatly
    toc: yes
    toc_float: yes
    number_sections : yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Intro


## The dataset

The dataset comes from a number guessing game running on Amazon Alexa. Users play a game with the voice assistant where the game randomly chooses a number between 1 to 100 and the user tries to guess the number. After a guess, the user is told whether their guess was too low or too high. The dataset includes 380,000 guesses across 50,000 games and 14,000 players. The dataset was sourced from [kaggle](https://www.kaggle.com/sdobson46/higher-or-lower-game). The dataset includes unique player IDs for all games as well as the date of the game and the outcome of the game. The dataset also allows for analysis of a player’s first game and information about whether the player returned to play more games. This dataset only includes completed games with no more than 15 guesses. The dataset excludes all guesses that Alexa did not understand or were invalid because they were not in the 1 to 100 number range. The dataset includes repeated guesses and guesses that conflict with previous hints provided by Alexa.

### Codebook

Dataframe `games` from `games.csv` file on kaggle.

* 1 row per game played
* 50881 rows total
* 22 columns:
  * `gameId` (factor w/ 50881 levels): Unique identifier for each game
  * `user` (int): Unique identifier for each player
  * `startTime` and `finishTime` (POSIX datetime): start and finish times of games.
  * `duration` (int): Duration of game in seconds.
  * `targetNum` (int): The randomly selected number between 1-100 that the player needs to guess
  * `numGuesses` (int): Number of guesses the player needed to guess the target number
  * `guess1` - `guess15` (int): The numbers which the user guessed.
    

## Research questions

Our primary research questions are:

1. How well do players approximate the optimal strategy?
  1.1. What proportion of users adopt binary search (the optimal strategy)?
  1.2. How does participant performance relate to this optimal benchmark?
  
2. How do players’ strategies change and/or improve over time?
  2.1 Do players' responses improve over time (as measured by the information gain of each guess)?
  2.2 Do players adopt or better approximate binary search over time or do they improve by adopting other strategies?
  
  
**TODO*: Ed mentioned he wanted us to look at the distribution of career lengths etc. We have these plots in the data_summary, but do you think we want to include any of that here/ in the writeup?


```{r}
# --- Setup --- #

# Load libraries
suppressMessages(library(tidyverse))
library(tidyverse)
library(RColorBrewer)
library(knitr)
library(lme4)

# Load data from data processing 
guesses <- read.csv('../data/guesses_processed.csv')
games <- read.csv('../data/games_processed.csv')
users <- read.csv('../data/users_processed.csv')

# Load simulation data
guesses.binary = read.csv('../data/guesses_binary_search.csv')
guesses.random = read.csv('../data/guesses_random_search.csv')

# Create color palette
paired <- brewer.pal(6, "Paired")
color1 <- paired[1]
color2 <- paired[2]
color3 <- paired[3]

color.binary = "green"
color.random = "red"
```


# How optimal are player strategies?

The guessing game affords an optimal strategy: binary search. At each guess, the player ought to select a guess which will eliminate the largest proportion of numbers from the remaining candidate numbers. Because the player has no information about where in the range of candidates the target number will fall, the best strategy is to pick the number at the centre of the range. In this way, roughly half of the candidates will be removed at each guess.

We define optimal search as `floor((upper+lower)/2)` where `upper` is the upper bound of the candidate range, and lower is the lower bound. At the start of the game, players have 100 candidates to choose among, so the optimal guess is 51 (or 50, which eliminates the same number of candidates on average: 49.5). The next guess will be 75 or 25 depending on whether the target number is above or below 51. The process continues, roughly halving the number of candidates at each guess until the target number is guessed (either because it happened to be in the centre of the range, or because only one number is left).

Using binary search, some numbers are easy to guess (50 requires only one guess), while others are hard to guess. However, no number needs more than 7 guesses to get correctly under binary search.

```{r}
guesses.binary %>% group_by(targetNum) %>% 
  summarise(numGuesses = n()/length(unique(gameId))) %>% 
  ggplot(aes(x = factor(targetNum), y = numGuesses)) + 
  geom_bar(fill=color.binary, stat = "identity") +
  theme_minimal() +
  scale_x_discrete(breaks = seq(0,100,by=5))+
  labs(
    title="Number of guesses needed for target number under binary search",
    x = "Target number",
    y = "Number of guesses required"
  )
```

```{r}
guesses.random %>% group_by(targetNum) %>% 
  summarise(numGuesses = n()/length(unique(gameId))) %>% 
  ggplot(aes(x = factor(targetNum), y = numGuesses)) + 
  geom_bar(fill=color.random, stat = "identity") +
  theme_minimal() +
  scale_x_discrete(breaks = seq(0,100,by=5))+
  labs(
    title="Number of guesses needed for target number under random search",
    x = "Target number",
    y = "Number of guesses required"
  )
```
```{r}
guesses %>% group_by(targetNum) %>% 
  summarise(numGuesses = n()/length(unique(gameId))) %>% 
  ggplot(aes(x = factor(targetNum), y = numGuesses)) + 
  geom_bar(stat = "identity") +
  theme_minimal() +
  scale_x_discrete(breaks = seq(0,100,by=5))+
  labs(
    title="Number of guesses for target number",
    x = "Target number",
    y = "Number of guesses required"
  )
```

```{r}
guesses %>% group_by(targetNum) %>% 
  summarise(numGuesses = n()/length(unique(gameId))) %>% 
  ggplot(aes(x = factor(targetNum), y = numGuesses)) + 
  geom_bar(stat = "identity") +
  geom_point(data = guesses.binary %>% 
             group_by(targetNum) %>% 
             summarise(numGuesses = n()/length(unique(gameId))),
    stat = "identity",
    color = color.binary) +
  geom_point(data = guesses.random %>% 
             group_by(targetNum) %>% 
             summarise(numGuesses = n()/length(unique(gameId))),
    stat = "identity",
    color = color.random) +
  scale_x_discrete(breaks = seq(0,100,by=5))+
  theme_minimal() +
  labs(
    title="Number of guesses for target number",
    x = "Target number",
    y = "Number of guesses required"
  )
```

## Number of guesses per game

Following binary search, then, at attempt `n`, we expect the number of candidates to be `100 / 2 ^ n`. Because `2 ^ 7 > 100`, we can deduce that no game would take longer than 7 guesses.

**Todo? Confirm with simulation. They do this on the [kaggle notebook](https://www.kaggle.com/sdobson46/interesting-observations) in Python which we could adapt. Could do a nice plot of the distribution of no. of guesses it takes for each number with optimal search. Might also be nice to have an implementation written here.**


By plotting the distribution of guesses per game, we can see that many games are completed suboptimally.

```{r}


games %>%
  ggplot(aes(x = factor(numGuesses))) + 
  geom_bar(fill=color1, stat = "count") +
  geom_point(data = guesses.random %>%
             group_by(gameId) %>%
             summarise(numGuesses = n()/length(unique(gameId))) %>%
             filter(numGuesses <= 15) %>% 
             mutate(numGuesses = factor(as.numeric(numGuesses))),
  stat = "count",
  color = color.random) +
  geom_point(data = guesses.binary %>%
             group_by(gameId) %>%
             summarise(numGuesses = n()/length(unique(gameId))) %>%
             mutate(numGuesses = factor(as.numeric(numGuesses))),
    stat = "count",
    color = color.binary) +
  theme_minimal() +
  labs(
    title="Distribution of number of guesses per game",
    x = "Number of guesses",
    y = "Number of games"
  )

```

```{r}
#Average number of guesses per game
mean(as.numeric(games$numGuesses))
sd(as.numeric(games$numGuesses))
```

Overall, around `r round(games %>%filter(numGuesses > 7) %>%nrow() / nrow(games)*100,2)`% of games required more than 7 guesses, and this is a conservative estimate for games completed sub-optimally, as most games would require fewer than 7 guesses using binary search.

## Mean no. guesses by user

Do all users tend to take suboptimally long to complete games? Or do some players consistently complete games in < 7 guesses?

Plotting the mean number of guesses/game for each user, grouping by the number of games each user played, we can see that there is a high spread across users. Some users who played 2-4 games consistently take more than 7 guesses to complete games.

```{r}

users %>%
  mutate(no_games_bin = cut(
        no_games,
        breaks = c(0, 1, 5, 200),
        labels = c("1", "2-4", "5+"),
        )
  ) %>%
  ggplot(aes(x=round(guesses.mean), fill=no_games_bin)) +
  geom_bar() +
  theme_minimal() +
  scale_fill_brewer(palette="Paired") +
  labs(
    title="Distribution of mean guesses per game across users",
    x = "Mean guesses per game",
    y = "Number of users",
    fill = "Games played"
  )

```


## What proportion of users and guesses are optimal?

The number of guesses metric, however, is not very discriminative. Some games will take longer than other even using binary search (no game can take longer than 7 guesses, while some games only take a single guess under binary search strategy). We can directly check if each guess is optimal by calculating the optimal guess at each decision point and checking whether the user's guess is equal to the optimal guess. Importantly, as discussed above wrt. 50/51, there are many situations in which two guesses will eliminate equal numbers of candidates on average, and so we treat both values (50 or 51) as optimal.

Firstly, we can plot the number of guesses that were optimal overall.

```{r}

guesses %>%
  mutate(isOptimal = factor(ifelse(isOptimal == 1, "Optimal", "Sub-optimal"))) %>%
  group_by(isOptimal) %>%
  summarise(prop = n() / nrow(guesses),
            .groups = "drop") %>%
  ggplot(aes(x = isOptimal, y = prop, fill=isOptimal)) + 
  geom_bar(stat = "identity") +
  geom_point(data = guesses.random %>%
              mutate(isOptimal = factor(ifelse(isOptimal == 1, "Optimal", "Sub-optimal"))) %>%
              group_by(isOptimal) %>%
              summarise(prop = n() / nrow(guesses),
                        .groups = "drop"),
             aes(x = isOptimal, y = prop),
             color= color.random)+
  scale_fill_brewer(palette = "Paired") +
  theme_minimal() +
  labs(
    title="What proportion of guesses were optimal?",
    x = "Optimality",
    y = "Proportion of guesses",
    fill = "Optimality"
  )

```

`r round(guesses %>% filter(isOptimal == 1) %>% nrow() / nrow(guesses),2)`% of guesses were optimal overall, which indicates that users were not using binary search two thirds of the time.

Again we can ask how the proportion of optimal guesses distributes across users (are most users making optimal guesses 1/3 of the time, or are 1/3 of the users making consistently optimal guesses).

A unimodal distribution with a mean at around 0.25, shows most users produce an optimal guess around a quarter of the time. However, a small number of users are consistently producing optimal guesses more than 80% of the time.

```{r}

users %>%
  ggplot(aes(x=propOptimal)) +
  geom_density(color=color1, size=1) +
  # geom_density(data = guesses.binary, color=color2, size=1) +
  geom_vline(xintercept = guesses.random %>% pull(isOptimal) %>% mean(), color=color.random)+
  geom_vline(xintercept = guesses.binary %>% pull(isOptimal) %>% mean(), color=color.binary)+
  theme_minimal() +
  labs(
    title="Proportion of guesses which were optimal by user",
    x = "Proportion of guesses that were optimal",
    y = "Density"
  )

```

Another interesting question is whether many of these optimal guesses are produced early on (when people know by rote to guess 50 > 25/75 etc), or whether they are produced later on, when fewer available options force a higher rate of optimal guesses by chance (as `n` decreases, the probability of choosing optimally ~`1/n` increases).

```{r}

guesses %>%
  mutate(isOptimal = factor(ifelse(isOptimal == 1, "Optimal", "Sub-optimal"))) %>%
  ggplot(aes(x = attemptNum)) + 
  geom_bar(aes(fill=isOptimal),position = "fill") +
  geom_point(data = guesses.binary %>%
                    group_by(attemptNum) %>% 
                    summarise(mean = mean(isOptimal)),
             aes(x=attemptNum,y=mean),
             color = color.binary)+
  geom_point(data = guesses.random %>%
                    group_by(attemptNum) %>% 
                    summarise(mean = mean(isOptimal)) %>% 
                    filter(attemptNum <= 15),
             aes(x=attemptNum,y=mean),
             color = color.random)+
  scale_fill_brewer(palette = "Paired") +
  theme_minimal() +
  labs(
    title="What proportion of guesses were optimal?",
    x = "N-th guess",
    y = "Proportion of guesses",
    fill = "Optimality"
  )

```

Primarily, the latter effect seems to drive optimality, however, there is a higher number of optimal guesses on the first guess than the second and third, which might be due to participants learning (or intuiting) that 50 is a good first guess.

The next plot shows how often the optimal guess was made on the n-th guess for a particular game beyond what might be expected by chance. 0 corresponds to performing at chance, negative number indicate performing below chance. This shows that, on average, the 9th guess and later are less often optimal than what might be expected by chance. This is because most games end before the 9th guess is made—therefore, players with many guesses tend to be poor players. The dropoff in the binary strategy is because of the accounting for making an optimal guess by chance.

```{r}
guesses %>%
  ggplot(aes(attemptNum, isOptimal-(1/(upperBound-lowerBound)))) +
  stat_summary_bin(fun.data="mean_cl_boot",
                   geom="pointrange",
                   binwidth = 1,
                   color=color2) +
  geom_smooth(method = 'lm') + 
  stat_summary_bin(data = guesses.binary,
                   fun.data="mean_cl_boot",
                   geom="pointrange",
                   binwidth = 1,
                   color=color.binary) +
  stat_summary_bin(data = guesses.random %>% filter(attemptNum < 15),
                   fun.data="mean_cl_boot",
                   geom="pointrange",
                   binwidth = 1,
                   color=color.random) +
  theme_minimal() +
  labs(
    title="Proportion of optimal guesses for the n-th guess beyond chance",
    x = "N-th guess",
    y="Proportion of optimal guesses - chance of optimal guess")+
  scale_x_continuous(breaks = 1:15) 
```

## How much information is gained by guesses compared to optimal guesses?

We can also define the expected amount of **information** gained by each guess. In Information Theory, "the [entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory) of a random variable is the average level of "information", "surprise", or "uncertainty" inherent in the variable's possible outcomes." In our case, because each candidate is as likely as the next, entropy is directly proportional to the number of candidates (the more candidates remaining, the more uncertain you are about which is correct).

We can calculate the entropy of our available candidates by summing `-P(x) * log2(P(x))` for each `x` where `P(x)` is the probability that each candidate in our set is the target number. Because the probability of each candidate is the same (`1 / n`), this reduces to `H = -n * ((1/n) * log2(1/n))`.

We can then calculate the **expected information gain (EIG)** of each guess, by calculating the entropy of the space *before* the guess was made and subtracting this from the expected entropy *after* the guess.

```{r}

guesses %>%
  ggplot(aes(x = EIG)) + 
  geom_density(color=color1, size=1) +
  geom_density(data = guesses.binary,
    color=color.binary, size=1) +
  geom_density(data = guesses.random,
    color=color.random, size=1) +
  theme_minimal() +
  labs(
    title="Distribution of EIG",
    x = "Expected Information Gain",
    y = "Density"
  )

```

```{r}
guesses %>%
  ggplot(aes(x = EIG)) +
  geom_density(size=0.5, data = guesses,
               fill=color1, color=color1, alpha=0.8) +
  geom_density(size=0.5, data = guesses.binary,
               fill=color.binary, color=color.binary, alpha=0.05) +
  geom_density(size=0.5, data = guesses.random,
               fill=color.random, color=color.random, alpha=0.05) +

  theme_minimal() +
  labs(
    title="Mean EIG across different games",
    x = "EIG",
    y = "Density",
    color = "Strategy"
  )

```

Finally, we can figure out what `n` (i.e. the number of candidates) *would* be if we had made the optimal guess at each decision point. So we can figure out what the expected entropy and optimal information gain would be.

```{r}

guesses %>%
  ggplot(aes(x = EIG.optimal)) + 
  geom_density(color=color1, size=1) +
  geom_density(data = guesses.binary,
    color=color.binary, size=1) +
  geom_density(data = guesses.random,
    color=color.random, size=1) +
  theme_minimal() +
  labs(
    title="Distribution of optimal EIG",
    x = "EIG of binary search",
    y = "Density"
  )

```

Therefore we can figure out what our information gain is relative to the optimal information gain. Here I've called this `EIG.relative` as in "relative to optimal", which is probably not the best name.

```{r}

guesses %>%
  ggplot(aes(x = EIG.relative)) +
  geom_density(size=1, color=color1) +
  geom_density(data = guesses.binary,
    color=color.binary, size=1) +
  geom_density(data = guesses.random,
    color=color.random, size=1) +
  ylim(0,2)+
  theme_minimal() +
  labs(
    title="Mean Relative EIG across different games",
    x = "Relative EIG",
    y = "Density"
  )

```

We can see that many guesses have an optimality of close to 1 (representing optimal guesses) with a long tail drifting off to very poor

Here they are binned.

```{r}

guesses %>%
  mutate(eig.bin = cut_interval(EIG.relative, length=0.1,
                                labels = seq(0.1, 1, 0.1))
         ) %>%
  group_by(eig.bin) %>%
  summarise(prop=n()/ nrow(guesses)) %>%
  ggplot(aes(x = eig.bin, y = prop)) + 
  geom_bar(stat = "identity", fill=color1) +
  theme_minimal() +
  labs(
    title="Distribution of optimal EIG",
    x = "EIG of binary search",
    y = "Density"
  )

```



# How do player strategies change over time?

## Does player performance improve?

```{r}

games %>%
  ggplot(aes(game_index, numGuesses)) +
  stat_summary_bin(fun.data="mean_cl_boot",
                   geom="pointrange",
                   binwidth = 5,
                   color=color2) +
  geom_smooth(method = 'lm') + 
  geom_hline(yintercept = guesses.random %>%
                          group_by(gameId) %>% 
                          summarise(n = n()) %>% 
                          pull(n) %>% mean(),
             color = color.random
  )+
  geom_hline(yintercept = guesses.binary %>%
                          group_by(gameId) %>% 
                          summarise(n = n()) %>% 
                          pull(n) %>% mean(),
             color = color.binary
  )+
  theme_minimal() + 
  labs(
    title="Number of guesses for n-th game of user",
    x = "No. previous games played by user",
    y = "Number of guesses")

  

```

Shows the mean number of guesses needed to complete each game against the "game index", or the number of games the user had played up until this point.

There does seem to be a downward trend but it's not as dramatic as I was expecting. Maybe this is because people who play for a long period of time are not very good (e.g. children, definition of madness etc), or because no_guesses is too weak of a measure (it can still be tough to get the number quickly even if you are using a good strategy). People who play for a long time are overall performing pretty well because they are under the average number of guesses, which is probably about as good as they can get because what number they get is dependent on random chance. Can we quantify an average number of guesses if you were always using optimal strategy for comparison?

```{r}

games %>%
  ggplot(aes(game_index, propOptimal)) +
  stat_summary_bin(fun.data="mean_cl_boot",
                   geom="pointrange",
                   binwidth = 5,
                   color=color2) +
  geom_smooth(method = 'lm') + 
  geom_hline(yintercept = guesses.random %>%
                          pull(isOptimal) %>% mean(),
             color = color.random
  )+
  geom_hline(yintercept = guesses.binary %>%
                          pull(isOptimal) %>% mean(),
             color = color.binary
  )+
  theme_minimal() + 
  ylim(0,1) +
  labs(
    title="Proportion of optimal guesses for n-th game of user",
    x = "No. previous games played by user",
    y = "Proportion of optimal guesses"
  )
  

```

Likewise, the proportion of optimal guesses markedly increases with the total number of games.

```{r}

games %>%
  ggplot(aes(game_index, EIG)) +
  stat_summary_bin(fun.data="mean_cl_boot",
                   geom="pointrange",
                   binwidth = 5,
                   color=color2) +
  geom_smooth(method = 'lm') + 
  geom_hline(yintercept = guesses.random %>%
                          pull(EIG) %>% mean(),
             color = color.random
  )+
  geom_hline(yintercept = guesses.binary %>%
                          pull(EIG) %>% mean(),
             color = color.binary
  )+
  theme_minimal() + 
  labs(
    title="Mean EIG  per guess for n-th game of user",
    x = "No. previous games played by user",
    y = "Mean information gain"
  )
  

```


```{r}
games %>%
  filter(no_user_games > 2) %>%
  ggplot(aes(game_index, EIG.relative)) +
  stat_summary_bin(fun.data="mean_cl_boot",
                   geom="pointrange",
                   binwidth = 5,
                   color=color1) +
  geom_smooth(method = 'lm', formula = y~x, color=color1) + 
  geom_hline(yintercept = guesses.random %>%
                          pull(EIG.relative) %>% mean(na.rm=T),
             color = color.random
  )+
  geom_hline(yintercept = guesses.binary %>%
                          pull(EIG.relative) %>% mean(na.rm=T),
             color = color.binary
  )+
  theme_minimal() + 
  labs(
    title="Mean relative EIG for n-th game of user",
    x = "No. previous games played by user",
    y = "Mean EIG relative to"
  )

```

```{r}

games %>%
  filter(no_user_games > 2) %>%
  mutate(
    no_user_games_bin = cut(
      no_user_games, breaks = c(1, 5, 10, 25, 50, 150),
      labels = c("1-5", "6-10", "11-25", "25-50", "50+"))
  ) %>%
  ggplot(aes(game_index, EIG.relative)) +
  stat_summary_bin(fun.data="mean_cl_boot",
                   geom="pointrange",
                   binwidth = 5,
                   mapping = aes(color=no_user_games_bin)) +
  # geom_smooth(method = 'lm', formula = y~x) + 
  geom_smooth(method = 'lm', formula = y~x,
              mapping=aes(color=no_user_games_bin)) + 
  geom_hline(yintercept = guesses.random %>%
                          pull(EIG.relative) %>% mean(na.rm=T),
             color = color.random
  )+
  geom_hline(yintercept = guesses.binary %>%
                          pull(EIG.relative) %>% mean(na.rm=T),
             color = color.binary
  )+
  theme_minimal() + 
  labs(
    title="Mean relative EIG for n-th game of user",
    x = "No. previous games played by user",
    y = "Mean EIG relative to"
  )
  

```

If we zoom in on the top 10 users we can see that their trajectories are not positive.

```{r}
games %>%
  filter(no_user_games > 50) %>%
  ggplot(aes(game_index, EIG.relative)) +
  # geom_smooth(method = 'lm', formula = y~x) + 
  geom_smooth(method = 'lm', formula = y~x,
              mapping=aes(color=factor(user)),
              se=F) + 
  geom_hline(yintercept = guesses.random %>%
                          pull(EIG.relative) %>% mean(na.rm=T),
             color = color.random
  )+
  geom_hline(yintercept = guesses.binary %>%
                          pull(EIG.relative) %>% mean(na.rm=T),
             color = color.binary
  )+
  theme_minimal() + 
  labs(
    title="Mean relative EIG for n-th game of user",
    x = "No. previous games played by user",
    y = "Mean EIG relative to"
  )
## Linear Models

```

Let's look at players relative mean EIG *relative* (again) to their own mean REIG across all games. Essentially let's ask, how did this users' performance compare to their mean performance across games.

```{r}

games <- merge(games, 
               users %>% select(user, EIG.relative) %>%
                 rename(EIG.relative.user = EIG.relative))

games %>%
  mutate(
    EIG.relative.self = EIG.relative / EIG.relative.user
  ) %>%
  filter(no_user_games > 2) %>%
  ggplot(aes(game_index, EIG.relative.self)) +
  stat_summary_bin(fun.data="mean_cl_boot",
                   geom="pointrange",
                   binwidth = 5,
                   color=color1) +
  geom_smooth(method = 'lm', formula = y~x, color=color1) + 
  theme_minimal() + 
  labs(
    title="REIG normalised to user mean for n-th game of user",
    x = "No. previous games played by user",
    y = "REIG vs career mean"
  )

```

Using this scale, we can see the effect is greatly attenuated: i.e. users are not improving much over the course of the game, the effect is caused by good players playing for longer and poor players stopping quickly.

**Simple Model**

A simple model with no control for user shows a **very** convincing effect of game_index on relative EIG.

```{r}

m.EIG.gi <- lm(EIG.relative ~ game_index, data=guesses)
summary(m.EIG.gi)

```

**LMEM Random Intercepts**

Random intercepts for ppt show an attenuated effect

```{r}

guesses$user <- as.factor(guesses$user)

lmm.EIG.gi <- lmer(EIG.relative ~ game_index + (1 | user), data=guesses)

summary(lmm.EIG.gi)

# null model
lmm.EIG.gi.null <- lmer(EIG.relative ~ (1 | user), data=guesses)

anova(lmm.EIG.gi, lmm.EIG.gi.null)

0.01 / 2.833e-04

```

You would expect a 1% improvement in performance for every ~35 games played.

**LMEM Random Intercepts + slopes**

Random intercepts & slopes for ppt show no effect

```{r}

guesses$user <- as.factor(guesses$user)

lmm.EIG.gi.slopes <- lmer(EIG.relative ~ game_index + (game_index | user), data=guesses)

summary(lmm.EIG.gi.slopes)

# null model
lmm.EIG.gi.slopes.null <- lmer(EIG.relative ~ (game_index | user), data=guesses)

anova(lmm.EIG.gi.slopes, lmm.EIG.gi.slopes.null)

0.01 / 2.833e-04

```

**Remove players with < 2 games**

```{r}

guesses$user <- as.factor(guesses$user)

lmm.EIG.gi.multi <- lmer(EIG.relative ~ game_index + (game_index | user),
                         data=guesses %>% filter(no_user_games > 1))

summary(lmm.EIG.gi.multi)

# null model
lmm.EIG.gi.multi.null <- lmer(EIG.relative ~ (game_index | user),
                              data=guesses %>% filter(no_user_games > 1))

anova(lmm.EIG.gi.multi, lmm.EIG.gi.multi.null)

0.01 / 2.833e-04

```

**Check with numGuesses**

The effect of numGuesses is not significant

```{r}

lmm.no.guesses <- lmer(numGuesses ~ game_index + (1 | user),
                         data=games %>% filter(no_user_games > 1))

summary(lmm.no.guesses)

# null model
lmm.no.guesses.null <- lmer(numGuesses ~ (1 | user),
                              data=games %>% filter(no_user_games > 1))

anova(lmm.no.guesses, lmm.no.guesses.null)

0.01 / 2.833e-04

```

## Do players get faster?

Finally, let's look at whether players get faster over the course of their career?

```{r}
games %>%
  ggplot(aes(game_index, duration/numGuesses)) +
  stat_summary_bin(fun.data="mean_cl_boot",
                   geom="pointrange",
                   binwidth = 5,
                   color=color2) +
  geom_smooth(method = 'lm') + 
  theme_minimal() + 
  labs(
    title="Duration per guess of n-th game of user",
    x = "No. previous games played by user",
    y = "Duration per guess in seconds"
  )
```



```{r}

m1 <- lm(numGuesses ~ game_index, data=games)
summary(m1)

```

A linear model shows a strong relationship between numGuesses and game_index (you expect to make one fewer guess about every 300 games).

```{r}

model.game_index.guesses.null <- lmer(numGuesses ~ (1 + game_index | user), data=games)

summary(model.game_index.guesses.null)

model.game_index.guesses <- lmer(numGuesses ~ game_index + (1 + game_index | user), data=games)

summary(model.game_index.guesses)

anova(model.game_index.guesses, model.game_index.guesses.null)

```

A linear mixed effects model (which takes into account the variance between participants), shows a stronger relationship (it predicts you will make one fewer guess every 150 games). A likelihood ratio test against a null model shows the effect to be significant.