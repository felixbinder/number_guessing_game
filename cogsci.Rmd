---
title: "cogsci"
author: "Cameron Jones"
date: "02/02/2021"
output:
  html_document:
    highlight: kate
    theme: flatly
    toc: yes
    toc_float: yes
---

# Setup

```{r}

# Load libraries
suppressMessages(library(tidyverse))
library(tidyverse)
library(RColorBrewer)
library(knitr)
library(lmerTest)
library(BSDA)

# Load data (and preprocess if this hasn't already been done).
source("read_data.R")

# Create color palette
paired <- brewer.pal(6, "Paired")
color1 <- paired[1]
color2 <- paired[2]
color3 <- paired[3]

color.binary = "green"
color.random = "red"
color.human = "blue"

```

# Cost Measures

Calculate

1) Interval size
2) Midpoint
3) No. borrows & carries
4) No. Operations

```{r}

guesses <- guesses %>%
  mutate(

    # Size measures
    interval = upperBound - lowerBound,
    meanBound = (upperBound + lowerBound) / 2,
  
    # Subtraction measures
    interval = upperBound - lowerBound,
    lb.mod10.0 = lowerBound %% 10 == 0,
    lb.lt.10 = lowerBound < 10,
    sub.borrow = (upperBound %% 10) < (lowerBound %% 10),
    sub.tens.eq = (upperBound %/% 10) == (lowerBound %/% 10),
  
    # Division measures
    interval.odd = (interval %% 2 == 1),
    interval.tens.odd = ((interval %/% 10) %% 2) == 1,
    interval.lt.10 = interval < 10,
  
    # Addition measures
    J = interval / 2,
    add.carry = ((J %% 10) + (lowerBound %% 10)) >= 10,
    j.lt.10 = J < 10,
    j.mod10.0 = (J %% 10) == 0
  ) %>%
  rowwise() %>%
  mutate(
    # Wrapped measures
    carries = sum(sub.borrow, add.carry, interval.odd, interval.tens.odd),
    ops = (1 - lb.lt.10) + (1 - lb.mod10.0)  + # Subtraction
      (1 - interval.lt.10) + 1 + # Division
      (1 - (j.lt.10 | lb.lt.10)) + (1 - (j.mod10.0 | lb.mod10.0))
  )
  
```

Calculate the same measures under the assumption users update their bounds "lazily". I.e. When they guess 50 and get feedback "higher", they update their lower bound to 50 rather than 51.

```{r}

# Same calculations with adjusted bounds
guesses.adj <- guesses %>%
  mutate(
    
    # Adjusted lower bound for lazy updating (assuming represents initial lb as 0)
    lowerBound.adj = lowerBound - 1,
    
    # Adjusted upper bound for lazy updating
    upperBound.adj = case_when(
      upperBound == 100 ~ 100,  # No adjustment when U = 100
      TRUE ~ upperBound + 1  # If U has moved, increment by 1 to simulate lazy updating
    ),
    
    # Size measures
    interval = upperBound.adj - lowerBound.adj,
    meanBound = (upperBound.adj + lowerBound.adj) / 2,

    # Subtraction measures
    lb.mod10.0 = lowerBound.adj %% 10 == 0,
    lb.lt.10 = lowerBound.adj < 10,
    sub.borrow = (upperBound.adj %% 10) < (lowerBound.adj %% 10),
    sub.tens.eq = (upperBound.adj %/% 10) == (lowerBound.adj %/% 10),
  
    # Division measures
    interval.odd = (interval %% 2 == 1),
    interval.tens.odd = ((interval %/% 10) %% 2) == 1,
    interval.lt.10 = interval < 10,
  
    # Addition measures
    J = interval / 2,
    add.carry = ((J %% 10) + (lowerBound.adj %% 10)) >= 10,
    j.lt.10 = J < 10,
    j.mod10.0 = (J %% 10) == 0,
  ) %>%
  rowwise() %>%
  mutate(
    # Wrapped measures
    carries = sum(sub.borrow, add.carry, interval.odd, interval.tens.odd),
    ops = (1 - lb.lt.10) + (1 - lb.mod10.0)  + # Subtraction
      (1 - interval.lt.10) + 1 + # Division
      (1 - (j.lt.10 | lb.lt.10)) + (1 - (j.mod10.0 | lb.mod10.0))
  )

```

## Test lazy updating hypothesis

Compare the AIC of full models constructed on the raw data vs the data after adjusting for lazy updating.

```{r}

# Raw data

m.all = lmer(EIG.relative ~ interval + interval + meanBound + carries + ops + (1 | user),
             data=guesses, REML = F)
summary(m.all)

```

```{r}

# Lazy updating adjusted

m.adj = lmer(EIG.relative ~ interval + interval + meanBound + carries + ops + (1 | user),
             data=guesses.adj, REML = F)

summary(m.adj)

```

AIC of the model run on the adjusted data is lower, therefore we assume that users *do* update bounds lazily and use the adjusted dataset for the rest of our analyses.

```{r}

AIC(m.all)

AIC(m.adj)
```


# Simulated Data

## Summary stats

Find mean and sd of EIG for real and simulated datasets

```{r}

mean(guesses.adj$EIG)
mean(guesses.binary$EIG)
mean(guesses.random$EIG)

```

```{r}

sd(guesses.adj$EIG)
sd(guesses.binary$EIG)
sd(guesses.random$EIG)

```

## Z-tests

We test whether random and optimal guessing are significantly different from human guesses.

### Random guessing

```{r}

z.test(guesses.adj$EIG, guesses.adj$EIG.random, sigma.x = sd(guesses.adj$EIG), sigma.y=sd(guesses.adj$EIG.random))

# z.test(guesses.adj$EIG, guesses.random$EIG, sigma.x = sd(guesses.adj$EIG), sigma.y=sd(guesses.random$EIG))

```

### Optimal Guessing
```{r}

z.test(guesses.adj$EIG, guesses.adj$EIG.optimal, sigma.x = sd(guesses.adj$EIG), sigma.y=sd(guesses.adj$EIG.optimal))

# z.test(guesses.adj$EIG, guesses.random$EIG, sigma.x = sd(guesses.adj$EIG), sigma.y=sd(guesses.random$EIG))

```


## Plot EIG between datasets

We group EIG by (simulated) user and plot the distribition of mean EIG for each user, split by dataset.

```{r}

# Create df of human users
users <- guesses.adj %>%
  group_by(user) %>%
  summarise(
    EIG = mean(EIG),
    EIG.relative = mean(EIG.relative)
  )

# Create users for simulated optimal data
games.binary <- guesses.binary %>%
  group_by(gameId) %>%
  summarise(
    EIG = mean(EIG),
    EIG.relative = mean(EIG.relative)
  )

# Sample from real user distribition
games.binary$user <- sample(games$user, nrow(games.binary), replace = T)
users.binary <- games.binary %>%
  group_by(user) %>%
  summarise(
    EIG = mean(EIG),
    EIG.relative = mean(EIG.relative)
  )

# Create users for random simulated data
games.random <- guesses.random %>%
  group_by(gameId) %>%
  summarise(
    EIG = mean(EIG),
    EIG.relative = mean(EIG.relative)
  )

# Sample from real user distribition
games.random$user <- sample(games$user, nrow(games.random), replace = T)
users.random <- games.random %>%
  group_by(user) %>%
  summarise(
    EIG = mean(EIG),
    EIG.relative = mean(EIG.relative)
  )

# Create df with real, random, and binary users

users$dataset = "Human Guesses"
users.binary$dataset = "Optimal Strategy"
users.random$dataset = "Random"

all.users <-rbind(users.binary, users.random, users %>% select(user, EIG, EIG.relative, dataset))


```


```{r}


all.users %>%
  mutate(
    dataset = factor(dataset,
                     levels = c("Random", "Human Guesses", "Optimal Strategy"))
    ) %>%
  ggplot(aes(x = EIG, fill=dataset)) + 
  geom_density(alpha=0.7, size=0.5, color="#00000000") +
  theme_minimal() +
  xlim(0, 1.5) +
  scale_fill_brewer(palette="Set1") +
  scale_color_brewer(palette="Set1") +
  labs(
    title="Distribution of Expected Information Gain",
    x = "Expected Information Gain",
    y = "Density",
    color="Dataset",
    fill="Dataset"
  )

```
# Heatmap Visualizations

These are the visualizations used in Figure 3

Figure 3A: Frequency of guesses by upper and lower bounds.

```{r}

guesses.bounds <- guesses.adj %>%
  group_by(lowerBound.adj, upperBound.adj) %>%
  summarise(n = n(),
            EIG.relative = mean(EIG.relative),
            .groups="drop")


guesses.bounds %>%
  ggplot(aes(x = lowerBound.adj, y = upperBound.adj, fill = log10(n))) +
  geom_raster() + 
  theme_minimal() + 
  labs(
    # title = "Frequency of intervals",
    fill='Frequency\n(log)'
  )+
  xlab("Lower bound")+
  ylab("Upper bound")+
    theme(text = element_text(size = 18),aspect.ratio = 1)

```

Figure 3B: rEIG by upper and lower bound.

```{r}

guesses.bounds %>%
  ggplot(aes(x = lowerBound.adj, y = upperBound.adj, fill = EIG.relative)) +
  geom_raster() + 
  theme_minimal() + 
  scale_fill_distiller(palette="RdYlGn", direction = 1) +
  labs(
    # title = "rEIG per interval",
    fill='rEIG'
  )+
  xlab("Lower bound")+
  ylab("Upper bound")+
theme(text = element_text(size = 20),aspect.ratio = 1)

```




# Full Model

Here we run LMEMs to measure the effects of each of the cost measures.

We use the full adjusted model above to measure the marginal effect of each measure when controlling for the others.

```{r}

# Full model
summary(m.adj)

```

Below are the coefficients used in Table 1. We standardize the coefficients and standard error.

```{r}

sds = c(1, sd(guesses.adj$interval), sd(guesses.adj$meanBound), sd(guesses.adj$carries), sd(guesses.adj$ops))

sds = sds / sd(guesses.adj$EIG.relative)

sds[1] = 1
coefs = summary(m.adj)$coef
coefs[,1] = coefs[,1] * sds
coefs[,2] = coefs[,2] * sds

coefs
```


# Interval size

REIG tends to lower as interval size increases. With a few expected exceptions at 25, 50, 100. In general this fits with the hypothesis that it's harder to do the optimal calculation for high intervals.

Below we plot the effect of interval on REIG.

```{r}

p.interval <- guesses.adj %>%
  # group_by(user) %>%
  # mutate(rEIG.user.mean = mean(EIG.relative),
  #        rEIGn = EIG.relative / rEIG.user.mean) %>%
  group_by(interval) %>%
  summarise(EIG.relative = mean(EIG.relative)) %>%
  ggplot(aes(interval, EIG.relative)) + 
  stat_summary(fun = "mean", geom = "point", color = "#444444",
               size=1.5) + 
  geom_smooth(method = "lm", formula = "y ~ x", se = T,
              color="#FF0022") + 
  theme_minimal() + 
  labs(
    y = "rEIG",
    x = "Interval Size"
  ) + 
  theme(
      # Text
    panel.grid.minor = element_line(size = 0.5),
    panel.grid.major = element_line(size = 1),
      # Text
    axis.title.x = element_text(size=22, margin = margin(t = 10, r = 0, b = 0, l = 0)),
    axis.title.y = element_text(size=22, margin = margin(t = 0, r = 10, b = 0, l = 0)),
    axis.text = element_text(size=15)
)

p.interval

```

```{r}

# Save figure

# ggsave("reig-interval.png", p.interval, bg = "transparent", width=7, height=5)

```

A linear model confirms the negative effect of interval size on rEIG.

```{r}

# Interval model
m.interval = lmer(EIG.relative ~ interval + (1 | user),
             data=guesses.adj, REML = F)

summary(m.interval)

# Get exact df
summary(m.interval)$coef[,3]

```

This result holds where interval size is <50 (rejecting an adverse selection effect explanation).

```{r}

# Interval gt50 model
m.interval.gt50 = lmer(EIG.relative ~ interval + (1 | user),
             data=guesses.adj %>% filter(interval < 50), REML = F)

summary(m.interval.gt50)

coef(summary(m.interval.gt50))
```

# Mean bound size

Visualization of rEIG vs mean bound size.

```{r}

p.meanBound <- guesses.adj %>%
  group_by(meanBound) %>%
  summarise(EIG.relative = mean(EIG.relative)) %>%
  ggplot(aes(meanBound, EIG.relative)) + 
  stat_summary(fun = "mean", geom = "point", color = "#444444", size=1.5) + 
  geom_smooth(method = "lm", formula = "y ~ x", se = T,
              color="#FF0022", size=1.5) + 
  theme_minimal() + 
  labs(
    y = "rEIG",
    x = "Midpoint"
  ) + 
  theme(
    panel.grid.minor = element_line(size = 0.5),
    panel.grid.major = element_line(size = 1),
      # Text
    axis.title.x = element_text(size=22, margin = margin(t = 10, r = 0, b = 0, l = 0)),
    axis.title.y = element_text(size=22, margin = margin(t = 0, r = 10, b = 0, l = 0)),
    axis.text = element_text(size=15)
)

p.meanBound

```

LMEM shows a negative effect.

```{r}

# Mean Bound model
m.mb = lmer(EIG.relative ~ meanBound + (1 | user),
             data=guesses.adj, REML = F)

summary(m.mb)

# get df
summary(m.mb)$coef[2,3]


```

```{r}
# ggsave("reig-meanBound.png", p.meanBound, bg = "transparent", width=7, height=5)

```



# Carries & Borrows

Plot of rEIG vs carries.

```{r}

p.carry <- guesses.adj %>%
  ggplot(aes(carries, EIG.relative)) + 
  stat_summary(fun = "mean", geom = "point", color = "#444444",
               size=3) + 
  geom_smooth(method = "lm", formula = "y ~ x", se = T,
              color="#FF0022", size=1.5) + 
  theme_minimal() + 
  labs(
    y = "rEIG",
    x = "No. Carries"
  ) + 
  theme(
    panel.grid.minor = element_line(size = 0.5),
    panel.grid.major = element_line(size = 1),
      # Text
    axis.title.x = element_text(size=22, margin = margin(t = 10, r = 0, b = 0, l = 0)),
    axis.title.y = element_text(size=22, margin = margin(t = 0, r = 10, b = 0, l = 0)),
    axis.text = element_text(size=15)
)

p.carry

```

```{r}
# ggsave("reig-carry.png", p.carry, bg = "transparent", width=7, height=5)
```

LMEM shows negative effect.

```{r}

# Carry model
m.carry = lmer(EIG.relative ~ carries + (1 | user),
             data=guesses.adj, REML = F)

summary(m.carry)

```

```{r}
summary(m.carry)$coef[,3]

```

# Operations

Plot rEIG vs no. operations.

```{r}

guesses.adj %>%
  ggplot(aes(ops, EIG.relative)) + 
  stat_summary(fun = "mean", geom = "point") +
  geom_smooth(method = "lm", formula = "y ~ x", se = T) +
  # stat_summary(fun = "mean", geom = "bar", fill=color1) +
  # stat_summary(fun.data = "mean_cl_boot", geom = "errorbar", width = 0.2, alpha = 0.5) +
  theme_minimal() + 
  labs(
    y = "rEIG",
    x = "No. Single Digit Operations"
  )

```
Model shows this is a significant negative effect. However, the effect does not hold in the full model (above).

```{r}

# Ops model
m.ops = lmer(EIG.relative ~ ops + (1 | user),
             data=guesses.adj, REML = F)

summary(m.ops)

```

```{r}

#df
summary(m.ops)$coef[,3]

```



