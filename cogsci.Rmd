---
title: "cogsci"
author: "Cameron Jones"
date: "02/02/2021"
output:
  html_document:
    highlight: kate
    theme: flatly
    toc: yes
    toc_float: yes
---

# Setup

Load libraries and create useful variables

```{r}

# Load libraries
suppressMessages(library(tidyverse))
library(tidyverse)
library(RColorBrewer)
library(knitr)
library(lmerTest)
library(BSDA)

# Create color palette
paired <- brewer.pal(6, "Paired")
color1 <- paired[1]
color2 <- paired[2]
color3 <- paired[3]

color.binary = "green"
color.random = "red"
color.human = "blue"

```

# Data

Here we load the datasets (or preprocess them using `process_data.R` if they haven't already been generated).

```{r}

# Load data (and preprocess if this hasn't already been done).
source("read_data.R")

```

The dataset comes from a number guessing game running on Amazon Alexa. Users play a game with the voice assistant where the game randomly chooses a number between 1 to 100 and the user tries to guess the number. After a guess, the user is told whether their guess was too low or too high. The dataset includes 380,000 guesses across 50,000 games and 14,000 players. The dataset was sourced from [kaggle](https://www.kaggle.com/sdobson46/higher-or-lower-game). The dataset includes unique player IDs for all games as well as the date of the game and the outcome of the game. The dataset also allows for analysis of a playerâ€™s first game and information about whether the player returned to play more games. This dataset only includes completed games with no more than 15 guesses. The dataset excludes all guesses that Alexa did not understand or were invalid because they were not in the 1 to 100 number range. The dataset includes repeated guesses and guesses that conflict with previous hints provided by Alexa.

## Games

Dataframe `games` from `games.csv` file on kaggle.

* 1 row per game played
* 50881 rows total
* 22 columns:
  * `gameId` (factor w/ 50881 levels): Unique identifier for each game
  * `user` (int): Unique identifier for each player
  * `startTime` and `finishTime` (POSIX datetime): start and finish times of games.
  * `duration` (int): Duration of game in seconds.
  * `targetNum` (int): The randomly selected number between 1-100 that the player needs to guess
  * `numGuesses` (int): Number of guesses the player needed to guess the target number
  * `guess1` - `guess15` (int): The numbers which the user guessed.
  
  
## Guesses

We pivot the data longer so that each guess is on a new row. We remove any rows which contain unused guesses (i.e. NA). We also create a variety of variables to measure the *effectiveness* of each guess in different ways (i.e. how much does the guess reduce uncertainty about the target number)? We filter out guesses which are out of bounds.

We then have a second dataframe `guesses`, with:
  
* One row per guess made.
* 198487 rows total

We create the following variables:

* `response` (factor w/ 3 levels): Whether targetNum is "lower" or "higher" than the guess, or "correct".
* `lowerBound` and `upperBound` (int): Minimum and maximum possible values for `targetNum` given previous guesses.
* `numAvailable` (int): The number of possible options within bounds.
* `prob` (num): The probability of randomly choosing `targetNum` from guesses within bounds [0,1].
* `entropy` (num): The level of uncertainty of `targetNum` given bounds (`-1 * numAvailable * prob * log(prob)`).
* `infoGain` (num): The reduction in `entropy` from `guess`.
* `optimalGuess` (int): The optimal guess based on binary search.
* `outOfBounds` (int): Whether the guess is within (0) or outwith (1) bounds.
* `numExcluded` (int): The number of potential choices ruled out by the `guess`.
* `propExcluded` (num): The proportion of potential choices ruled out by `guess`.

## Simulated Data

We also generate two datasets of simulated data: `guesses.binary` (which assumes all users follow the optimal binary search strategy) and `guesses.random` which assumes users guess randomly. The code to generate this data can be found in the `models/` subdirectory.


# Cost Measures

We can characterize the optimal search strategy as an algorithm which attempts to find *M*, the mid-point between the upper bound (*U*) and the lower bound (*L*). This can be broken down into three arithmetical operations:

1. *I = U - L*
2. *J = I / 2*
3. *M = L + I*

where *I* is the interval between *U* and *L*, and *J* is half of this interval.

We constructed measures of processing difficulty for each of the arithmetical steps assumed to comprise the binary search algorithm. For each guess which was made by a user, we estimated the processing difficulty on each of these measures based on the upper and lower bounds available to the user when the guess was made. We measured how successful the Expected Information Gain (EIG) of the user's guess relative to the EIG of the optimal guess. We call this measure Relative Expected Information Gain (REIG). We constructed linear mixed effects models to predict REIG using our measures of arithmetical difficulty.

We calculate the following cost measures for each guess

1) Interval size (`U - L`)
2) Midpoint (`(U - L) / 2`)
3) No. borrows & carries
4) No. operations

```{r}

guesses <- guesses %>%
  mutate(

    # Size measures
    interval = upperBound - lowerBound,
    meanBound = (upperBound + lowerBound) / 2,
  
    # Subtraction measures
    lb.mod10.0 = lowerBound %% 10 == 0, # No subtraction necessary in ones-place;
                                        # No addition necessary in ones-place
    lb.lt.10 = lowerBound < 10, # No subtraction necessary in tens-place;
                                # No addition necessary in tens-place
    sub.borrow = (upperBound %% 10) < (lowerBound %% 10), # Borrow in ones-place
    sub.tens.eq = (upperBound %/% 10) == (lowerBound %/% 10),
  
    # Division measures
    interval.odd = (interval %% 2 == 1), # Carry in ones-place
    interval.tens.odd = ((interval %/% 10) %% 2) == 1, # Carry in tens-place
    interval.lt.10 = interval < 10, # No division necessary in tens-place
  
    # Addition measures
    J = interval / 2,
    add.carry = ((J %% 10) + (lowerBound %% 10)) >= 10, # Carry in ones-place
    j.lt.10 = J < 10, # No addition necessary in tens-place
    j.mod10.0 = (J %% 10) == 0 # No addition necessary in ones-place
  ) %>%
  rowwise() %>%
  mutate(
    # Aggregated measures
    carries = sum(sub.borrow, add.carry, interval.odd, interval.tens.odd),
    ops = (1 - lb.lt.10) + (1 - lb.mod10.0)  + # Subtraction
          (1 - interval.lt.10) + 1 + # Division
          (1 - (j.lt.10 | lb.lt.10)) + (1 - (j.mod10.0 | lb.mod10.0)) # Addition
  )
  
```

Calculate the same measures under the assumption users update their bounds "lazily". I.e. When they guess 50 and get feedback "higher", they update their lower bound to 50 rather than 51.

```{r}

# Same calculations with adjusted bounds
guesses.adj <- guesses %>%
  mutate(
    
    # Adjusted lower bound for lazy updating (assuming represents initial lb as 0)
    lowerBound.adj = lowerBound - 1,
    
    # Adjusted upper bound for lazy updating
    upperBound.adj = case_when(
      upperBound == 100 ~ 100,  # No adjustment when U = 100
      TRUE ~ upperBound + 1  # If U has moved, increment by 1 to simulate lazy updating
    ),
    
    # Size measures
    interval = upperBound.adj - lowerBound.adj,
    meanBound = (upperBound.adj + lowerBound.adj) / 2,

    # Subtraction measures
    lb.mod10.0 = lowerBound.adj %% 10 == 0,
    lb.lt.10 = lowerBound.adj < 10,
    sub.borrow = (upperBound.adj %% 10) < (lowerBound.adj %% 10),
    sub.tens.eq = (upperBound.adj %/% 10) == (lowerBound.adj %/% 10),
  
    # Division measures
    interval.odd = (interval %% 2 == 1),
    interval.tens.odd = ((interval %/% 10) %% 2) == 1,
    interval.lt.10 = interval < 10,
  
    # Addition measures
    J = interval / 2,
    add.carry = ((J %% 10) + (lowerBound.adj %% 10)) >= 10,
    j.lt.10 = J < 10,
    j.mod10.0 = (J %% 10) == 0,
  ) %>%
  rowwise() %>%
  mutate(
    # Wrapped measures
    carries = sum(sub.borrow, add.carry, interval.odd, interval.tens.odd),
    ops = (1 - lb.lt.10) + (1 - lb.mod10.0)  + # Subtraction
      (1 - interval.lt.10) + 1 + # Division
      (1 - (j.lt.10 | lb.lt.10)) + (1 - (j.mod10.0 | lb.mod10.0))
  )

```

## Test lazy updating hypothesis

Compare the AIC of full models constructed on the raw data vs the data after adjusting for lazy updating.

```{r}

# Raw data

m.all = lmer(EIG.relative ~ interval + interval + meanBound + carries + ops + (1 | user),
             data=guesses, REML = F)
summary(m.all)

```

```{r}

# Lazy updating adjusted

m.adj = lmer(EIG.relative ~ interval + interval + meanBound + carries + ops + (1 | user),
             data=guesses.adj, REML = F)

summary(m.adj)

```

AIC of the model run on the adjusted data is lower, therefore we assume that users *do* update bounds lazily and use the adjusted dataset for the rest of our analyses.

```{r}

AIC(m.all)

AIC(m.adj)
```


# Simulated Data

## Summary stats

Find mean and sd of EIG for real and simulated datasets

```{r}

mean(guesses.adj$EIG)
mean(guesses.binary$EIG)
mean(guesses.random$EIG)

```

```{r}

sd(guesses.adj$EIG)
sd(guesses.binary$EIG)
sd(guesses.random$EIG)

```

## Z-tests

We test whether random and optimal guessing are significantly different from human guesses.

### Random guessing

```{r}

z.test(guesses.adj$EIG, guesses.adj$EIG.random, sigma.x = sd(guesses.adj$EIG), sigma.y=sd(guesses.adj$EIG.random))

# z.test(guesses.adj$EIG, guesses.random$EIG, sigma.x = sd(guesses.adj$EIG), sigma.y=sd(guesses.random$EIG))

```

### Optimal Guessing
```{r}

z.test(guesses.adj$EIG, guesses.adj$EIG.optimal, sigma.x = sd(guesses.adj$EIG), sigma.y=sd(guesses.adj$EIG.optimal))

# z.test(guesses.adj$EIG, guesses.random$EIG, sigma.x = sd(guesses.adj$EIG), sigma.y=sd(guesses.random$EIG))

```


## Plot EIG between datasets

We group EIG by (simulated) user and plot the distribition of mean EIG for each user, split by dataset.

```{r}

# Create df of human users
users <- guesses.adj %>%
  group_by(user) %>%
  summarise(
    EIG = mean(EIG),
    EIG.relative = mean(EIG.relative)
  )

# Create users for simulated optimal data
games.binary <- guesses.binary %>%
  group_by(gameId) %>%
  summarise(
    EIG = mean(EIG),
    EIG.relative = mean(EIG.relative)
  )

# Sample from real user distribition
games.binary$user <- sample(games$user, nrow(games.binary), replace = T)
users.binary <- games.binary %>%
  group_by(user) %>%
  summarise(
    EIG = mean(EIG),
    EIG.relative = mean(EIG.relative)
  )

# Create users for random simulated data
games.random <- guesses.random %>%
  group_by(gameId) %>%
  summarise(
    EIG = mean(EIG),
    EIG.relative = mean(EIG.relative)
  )

# Sample from real user distribition
games.random$user <- sample(games$user, nrow(games.random), replace = T)
users.random <- games.random %>%
  group_by(user) %>%
  summarise(
    EIG = mean(EIG),
    EIG.relative = mean(EIG.relative)
  )

# Create df with real, random, and binary users

users$dataset = "Human Guesses"
users.binary$dataset = "Optimal Strategy"
users.random$dataset = "Random"

all.users <-rbind(users.binary, users.random, users %>% select(user, EIG, EIG.relative, dataset))


```


```{r}


all.users %>%
  mutate(
    dataset = factor(dataset,
                     levels = c("Random", "Human Guesses", "Optimal Strategy"))
    ) %>%
  ggplot(aes(x = EIG, fill=dataset)) + 
  geom_density(alpha=0.7, size=0.5, color="#00000000") +
  theme_minimal() +
  xlim(0, 1.5) +
  scale_fill_brewer(palette="Set1") +
  scale_color_brewer(palette="Set1") +
  labs(
    title="Distribution of Expected Information Gain",
    x = "Expected Information Gain",
    y = "Density",
    color="Dataset",
    fill="Dataset"
  )

```
# Heatmap Visualizations

These are the visualizations used in Figure 3

Figure 3A: Frequency of guesses by upper and lower bounds.

```{r}

guesses.bounds <- guesses.adj %>%
  group_by(lowerBound.adj, upperBound.adj) %>%
  summarise(n = n(),
            EIG.relative = mean(EIG.relative),
            .groups="drop")


guesses.bounds %>%
  ggplot(aes(x = lowerBound.adj, y = upperBound.adj, fill = log10(n))) +
  geom_raster() + 
  theme_minimal() + 
  labs(
    # title = "Frequency of intervals",
    fill='Frequency\n(log)'
  )+
  xlab("Lower bound")+
  ylab("Upper bound")+
    theme(text = element_text(size = 18),aspect.ratio = 1)

```

Figure 3B: rEIG by upper and lower bound.

```{r}

guesses.bounds %>%
  ggplot(aes(x = lowerBound.adj, y = upperBound.adj, fill = EIG.relative)) +
  geom_raster() + 
  theme_minimal() + 
  scale_fill_distiller(palette="RdYlGn", direction = 1) +
  labs(
    # title = "rEIG per interval",
    fill='rEIG'
  )+
  xlab("Lower bound")+
  ylab("Upper bound")+
theme(text = element_text(size = 20),aspect.ratio = 1)

```




# Full Model

Here we run LMEMs to measure the effects of each of the cost measures.

We use the full adjusted model above to measure the marginal effect of each measure when controlling for the others.

```{r}

# Full model
summary(m.adj)

```

Below are the coefficients used in Table 1. We standardize the coefficients and standard error.

```{r}

sds = c(1, sd(guesses.adj$interval), sd(guesses.adj$meanBound), sd(guesses.adj$carries), sd(guesses.adj$ops))

sds = sds / sd(guesses.adj$EIG.relative)

sds[1] = 1
coefs = summary(m.adj)$coef
coefs[,1] = coefs[,1] * sds
coefs[,2] = coefs[,2] * sds

coefs
```


# Interval size

REIG tends to lower as interval size increases. With a few expected exceptions at 25, 50, 100. In general this fits with the hypothesis that it's harder to do the optimal calculation for high intervals.

Below we plot the effect of interval on REIG.

```{r}

p.interval <- guesses.adj %>%
  # group_by(user) %>%
  # mutate(rEIG.user.mean = mean(EIG.relative),
  #        rEIGn = EIG.relative / rEIG.user.mean) %>%
  group_by(interval) %>%
  summarise(EIG.relative = mean(EIG.relative)) %>%
  ggplot(aes(interval, EIG.relative)) + 
  stat_summary(fun = "mean", geom = "point", color = "#444444",
               size=1.5) + 
  geom_smooth(method = "lm", formula = "y ~ x", se = T,
              color="#FF0022") + 
  theme_minimal() + 
  labs(
    y = "rEIG",
    x = "Interval Size"
  ) + 
  theme(
      # Text
    panel.grid.minor = element_line(size = 0.5),
    panel.grid.major = element_line(size = 1),
      # Text
    axis.title.x = element_text(size=22, margin = margin(t = 10, r = 0, b = 0, l = 0)),
    axis.title.y = element_text(size=22, margin = margin(t = 0, r = 10, b = 0, l = 0)),
    axis.text = element_text(size=15)
)

p.interval

```

```{r}

# Save figure

# ggsave("reig-interval.png", p.interval, bg = "transparent", width=7, height=5)

```

A linear model confirms the negative effect of interval size on rEIG.

```{r}

# Interval model
m.interval = lmer(EIG.relative ~ interval + (1 | user),
             data=guesses.adj, REML = F)

summary(m.interval)

# Get exact df
summary(m.interval)$coef[,3]

```

This result holds where interval size is <50 (rejecting an adverse selection effect explanation).

```{r}

# Interval gt50 model
m.interval.gt50 = lmer(EIG.relative ~ interval + (1 | user),
             data=guesses.adj %>% filter(interval < 50), REML = F)

summary(m.interval.gt50)

coef(summary(m.interval.gt50))
```

# Mean bound size

Visualization of rEIG vs mean bound size.

```{r}

p.meanBound <- guesses.adj %>%
  group_by(meanBound) %>%
  summarise(EIG.relative = mean(EIG.relative)) %>%
  ggplot(aes(meanBound, EIG.relative)) + 
  stat_summary(fun = "mean", geom = "point", color = "#444444", size=1.5) + 
  geom_smooth(method = "lm", formula = "y ~ x", se = T,
              color="#FF0022", size=1.5) + 
  theme_minimal() + 
  labs(
    y = "rEIG",
    x = "Midpoint"
  ) + 
  theme(
    panel.grid.minor = element_line(size = 0.5),
    panel.grid.major = element_line(size = 1),
      # Text
    axis.title.x = element_text(size=22, margin = margin(t = 10, r = 0, b = 0, l = 0)),
    axis.title.y = element_text(size=22, margin = margin(t = 0, r = 10, b = 0, l = 0)),
    axis.text = element_text(size=15)
)

p.meanBound

```

LMEM shows a negative effect.

```{r}

# Mean Bound model
m.mb = lmer(EIG.relative ~ meanBound + (1 | user),
             data=guesses.adj, REML = F)

summary(m.mb)

# get df
summary(m.mb)$coef[2,3]


```

```{r}
# ggsave("reig-meanBound.png", p.meanBound, bg = "transparent", width=7, height=5)

```



# Carries & Borrows

Plot of rEIG vs carries.

```{r}

p.carry <- guesses.adj %>%
  ggplot(aes(carries, EIG.relative)) + 
  stat_summary(fun = "mean", geom = "point", color = "#444444",
               size=3) + 
  geom_smooth(method = "lm", formula = "y ~ x", se = T,
              color="#FF0022", size=1.5) + 
  theme_minimal() + 
  labs(
    y = "rEIG",
    x = "No. Carries"
  ) + 
  theme(
    panel.grid.minor = element_line(size = 0.5),
    panel.grid.major = element_line(size = 1),
      # Text
    axis.title.x = element_text(size=22, margin = margin(t = 10, r = 0, b = 0, l = 0)),
    axis.title.y = element_text(size=22, margin = margin(t = 0, r = 10, b = 0, l = 0)),
    axis.text = element_text(size=15)
)

p.carry

```

```{r}
# ggsave("reig-carry.png", p.carry, bg = "transparent", width=7, height=5)
```

LMEM shows negative effect.

```{r}

# Carry model
m.carry = lmer(EIG.relative ~ carries + (1 | user),
             data=guesses.adj, REML = F)

summary(m.carry)

```

```{r}
summary(m.carry)$coef[,3]

```

# Operations

Plot rEIG vs no. operations.

```{r}

guesses.adj %>%
  ggplot(aes(ops, EIG.relative)) + 
  stat_summary(fun = "mean", geom = "point") +
  geom_smooth(method = "lm", formula = "y ~ x", se = T) +
  # stat_summary(fun = "mean", geom = "bar", fill=color1) +
  # stat_summary(fun.data = "mean_cl_boot", geom = "errorbar", width = 0.2, alpha = 0.5) +
  theme_minimal() + 
  labs(
    y = "rEIG",
    x = "No. Single Digit Operations"
  )

```
Model shows this is a significant negative effect. However, the effect does not hold in the full model (above).

```{r}

# Ops model
m.ops = lmer(EIG.relative ~ ops + (1 | user),
             data=guesses.adj, REML = F)

summary(m.ops)

```

```{r}

#df
summary(m.ops)$coef[,3]

```



